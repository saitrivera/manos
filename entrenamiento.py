import cv2
import mediapipe as mp
import numpy as np

# Inicializar el mÃ³dulo de MediaPipe para la detecciÃ³n de manos
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)
mp_draw = mp.solutions.drawing_utils

# Inicializar la cÃ¡mara web
cap = cv2.VideoCapture(0)

# Mapeo de gestos a emojis y significados
gestos_dict = {
    "thumb_up": ("ğŸ‘", "golpe"),
    "thumb_down": ("ğŸ‘", "DesaprobaciÃ³n / No me gusta"),
    "peace": ("âœŒï¸", "hola"),
    "rock_on": ("ğŸ¤˜", "Actitud de rock"),
    "fist": ("ğŸ‘Š", "Fuerza / Luchar"),
    "ok": ("ğŸ‘Œ", "okey"),
    "praying": ("ğŸ™", "Por favor / Gracias"),
    "offering": ("ğŸ¤²", "Ofrecer algo"),
    "muscle": ("ğŸ’ª", "exelente"),
    "stop": ("ğŸ¤š", "Alto / Detente"),
    "raise_hand": ("âœ‹", "Alto / Detente"),
    "wave": ("ğŸ‘‹", "Hola / AdiÃ³s"),
    "five_fingers": ("ğŸ–", "AdiÃ³s"),
    "rock_sign": ("ğŸ¤Ÿ", "Actitud de rock"),
    "nailpolish": ("ğŸ’…", "Cuidado personal / Belleza"),
    "vulcan_greeting": ("ğŸ––", "Larga vida y prosperidad"),
    "open_hands": ("ğŸ‘", "Receptividad / Recibir"),
    "left_point": ("ğŸ‘ˆ", " izquierda"),
    "right_point": ("ğŸ‘‰", "derecha"),
    "hug": ("ğŸ‘", "Abrazo"),
    "call_me": ("ğŸ¤™", "Llamada / Conectando"),
    "shaka": ("ğŸ¤™", "Aloha / Buena onda"),
    "clap": ("ğŸ‘", "Aplauso"),
    "raised_fist": ("âœŠ", "Resistencia / Fuerza"),
}

def detectar_gesto(hand_landmarks):
    """
    FunciÃ³n para detectar gestos bÃ¡sicos de la mano basados en las coordenadas de los puntos de referencia.
    """
    if hand_landmarks:
        # Extraer las posiciones de los puntos de referencia (landmarks)
        landmarks = hand_landmarks.landmark
        
        # Pulgar
        thumb_tip = landmarks[mp_hands.HandLandmark.THUMB_TIP]
        thumb_base = landmarks[mp_hands.HandLandmark.THUMB_CMC]
        
        # Ãndice y medio
        index_tip = landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP]
        middle_tip = landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]
        
        # Anular y meÃ±ique
        ring_tip = landmarks[mp_hands.HandLandmark.RING_FINGER_TIP]
        pinky_tip = landmarks[mp_hands.HandLandmark.PINKY_TIP]

        # Gesto de "Pulgar hacia arriba" (ğŸ‘)
        if thumb_tip.y < thumb_base.y and all(landmarks[i].y > landmarks[i - 1].y for i in range(4, 20, 4)):
            return gestos_dict["thumb_up"]
        
        # Gesto de "Pulgar hacia abajo" (ğŸ‘)
        if thumb_tip.y > thumb_base.y and abs(index_tip.x - thumb_tip.x) > 0.1:
            return gestos_dict["thumb_down"]

        # Gesto de "Paz" (âœŒï¸)
        if abs(index_tip.x - middle_tip.x) < 0.1 and abs(index_tip.y - middle_tip.y) < 0.1:
            if all(landmarks[i].y < landmarks[i - 1].y for i in range(8, 20, 4)):
                return gestos_dict["peace"]
        
        # Gesto de "OK" (ğŸ‘Œ)
        if abs(thumb_tip.x - index_tip.x) < 0.05 and abs(thumb_tip.y - index_tip.y) < 0.05:
            return gestos_dict["ok"]

        # Gesto de "PuÃ±o cerrado" (ğŸ‘Š)
        if all(landmarks[i].y < landmarks[i - 1].y for i in range(4, 20, 4)):
            return gestos_dict["fist"]

        # Gesto de "Mano abierta" (ğŸ–)
        if all(landmarks[i].y < landmarks[i - 1].y for i in range(8, 20, 4)):
            return gestos_dict["five_fingers"]

        # Gesto de "Musculo" (ğŸ’ª)
        if abs(index_tip.x - pinky_tip.x) < 0.05 and all(landmarks[i].y > landmarks[i - 1].y for i in range(5, 20, 4)):
            return gestos_dict["muscle"]
        
        # Gesto de "SeÃ±alando izquierda" (ğŸ‘ˆ)
        if index_tip.x < thumb_tip.x:
            return gestos_dict["left_point"]
        
        # Gesto de "SeÃ±alando derecha" (ğŸ‘‰)
        if index_tip.x > thumb_tip.x:
            return gestos_dict["right_point"]

        # Gesto de "Abrazo" (ğŸ‘)
        if abs(index_tip.x - pinky_tip.x) < 0.1 and all(landmarks[i].y < landmarks[i - 1].y for i in range(4, 20, 4)):
            return gestos_dict["hug"]

        # Gesto de "Llamada" (ğŸ¤™)
        if abs(thumb_tip.x - pinky_tip.x) < 0.05 and abs(index_tip.x - pinky_tip.x) > 0.15:
            return gestos_dict["call_me"]
        
        # Gesto de "Shaka" (ğŸ¤™)
        if abs(thumb_tip.x - pinky_tip.x) < 0.05 and abs(index_tip.x - pinky_tip.x) < 0.1:
            return gestos_dict["shaka"]
        
        # Gesto de "Aplauso" (ğŸ‘)
        if all(landmarks[i].y < landmarks[i - 1].y for i in range(5, 20, 4)) and abs(thumb_tip.y - index_tip.y) < 0.1:
            return gestos_dict["clap"]

        # Gesto de "Fist raised" (âœŠ)
        if abs(thumb_tip.x - pinky_tip.x) < 0.05 and abs(index_tip.x - middle_tip.x) > 0.2:
            return gestos_dict["raised_fist"]

    return "Desconocido: Gestos no reconocidos"

while True:
    # Capturar una imagen desde la cÃ¡mara
    ret, frame = cap.read()

    # Convertir la imagen a RGB
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Procesar la imagen para detectar las manos
    results = hands.process(frame_rgb)

    # Dibujar las anotaciones en la imagen (puntos de la mano)
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Detectar gestos y agregar la descripciÃ³n correspondiente
            gesto = detectar_gesto(hand_landmarks)
            
            # Verificar si el gesto es una tupla con emoji y significado
            if isinstance(gesto, tuple) and len(gesto) == 2:
                emoji, significado = gesto
                # Mostrar el gesto y su descripciÃ³n en la imagen
                cv2.putText(frame, f"{emoji} - {significado}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)
            else:
                # Si no es un gesto vÃ¡lido, mostrar un mensaje de error
                cv2.putText(frame, gesto, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)

    # Mostrar la imagen con los gestos detectados
    cv2.imshow('Reconocimiento de Gestos de Mano', frame)

    # Romper el bucle si se presiona la tecla 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Liberar la cÃ¡mara y cerrar las ventanas de OpenCV
cap.release()
cv2.destroyAllWindows()
